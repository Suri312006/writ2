# Questions / Concerns / Uncertainties

It's getting a bit heavy in the quarter in terms of workload, so I'm
a bit worried that getting all the words out on the page is going to be
a bit of a time crunch / not my finest work.


# The question I want to answer:
How does existing copyright law apply to the usage of AI output, especially
in the field of software engineering?

# My thesis statement:
For those concerned with the legality of the software they produce, the usage
of AI tools that produce code should be avoided as their trustworthiness is
dubious and they will become susceptible to copyright law in the near future.

# Essay Structure Background Information

# History of copyright.
- Go down into the history of copyright, what its
definition is, and how it has been interpreted in the past. Really tie
it in for the reader so it's fully clear how my argument builds upon
this foundational information.
  - The book by Stokes should have a lot of relevant information that
    I can summarize and cite in this section.

-An aside / short paragraph about the overlap between copyright and code.
Talk about Google vs. Oracle and how modern software practices software
through the idea of licenses. It's really important that this point
gets understood by the reader, so add examples / pictures from GitHub?
  - The article by Harvard Law Review going over the Google v. Oracle
    case should give enough information to summarize the technical details
    for the audience so they have a basic understanding. I can cite one
    of the most widely used licenses and show how they apply to the code
    in repositories, i.e., the MIT license.

- Usage of AI tools in software engineering. Background information about
how artificial intelligence tools have broken into the industry today
and the prevalence of their usage. I can cite the paper:
  - "Recent research [15] has demonstrated that large PLG [Programming
    Language Generation] models such as GPT-J [89] can accomplish
    computer science assignments for students without triggering MOSS
    [76], a widely used academic plagiarism detection tool." (page 2,
    1st paragraph, academic paper)

# Dangers of Artificial Intelligence Regarding Code Generation

- It's already hard to fit AI-generated anything into a box right now.
    - Thomas's newspaper talks about how implementing regulation against
    AI-made works has failed in the UK.

- The lack of rules has allowed "rule breakage" of honest, well-intentioned
standards already placed within the community, such as how AI companies
are ignoring robots.txt.
  - This paragraph is probably going to be a bit longer, or
    I might split it up into two—one where I explain what a
    robots.txt is, and the second going into the dishonest behavior.
    https://mjtsai.com/blog/2024/06/24/ai-companies-ignoring-robots-txt/

- Code is being written today that uses the output of these thinking
machines—code that's going to be integrated into existing
codebases. Any ruling in the future is going to impact code that was
written today. It's a very murky area to be in as a company right now.

- Additionally, as a company, it can be a liability for your own code
through the usage of these tools because there is no guarantee that they
aren't harvesting your code as they write it.
    More of a cybersecurity angle.

# Steps Being Taken to Track It

This part of my research paper is going to delve deep into the ideas and
presentations made in the research paper about back-tracking the results of
artificial intelligence to their source. Using this evidence, I plan to make
a logical argument that in the future, with technology like this advancing,
if we can find the source of any source code, and if it's similar enough,
it makes a valid enough case for a copyright violation. Using this, I'll
argue that for those who are concerned about the legality of their code,
it's better to avoid using tools that spit out code, as the risk can be
too high.

# Conclusion
Summarize my point with an emphasis on my thesis.
